{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed409f8b-dc92-461c-bf00-9be23cef9bc1",
   "metadata": {},
   "source": [
    "## Subquestion Query Engine as a workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382b644d-98f5-4603-ace6-5f4754efc0a3",
   "metadata": {},
   "source": [
    "#### Note: Create and Use environment llamindex_workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88be2e09-f78c-4b5b-b8c6-774999e7a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index-core llama-index-llms-openai llama-index-embeddings-openai llama-index-readers-file \n",
    "# !pip install llama-index-utils-workflow\n",
    "# llama-index-utils-workflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a96361-d2a6-4376-b95f-2affd27393e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex, \n",
    "    StorageContext, \n",
    "    load_index_from_storage)\n",
    "from llama_index.core.tools import (\n",
    "    QueryEngineTool, \n",
    "    ToolMetadata)\n",
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Context\n",
    ")\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from llama_index.utils.workflow  import draw_all_possible_flows\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a297ba-2b6a-4e10-b179-8edfce6eb8a8",
   "metadata": {},
   "source": [
    "# Define the Sub Question Query Engine as a Workflow\n",
    "\n",
    "* Our StartEvent goes to `query()`, which takes care of several things:\n",
    "  * Accepts and stores the original query\n",
    "  * Stores the LLM to handle the queries\n",
    "  * Stores the list of tools to enable sub-questions\n",
    "  * Passes the original question to the LLM, asking it to split up the question into sub-questions\n",
    "  * Fires off a `QueryEvent` for every sub-question generated\n",
    "\n",
    "* QueryEvents go to `sub_question()`, which instantiates a new ReAct agent with the full list of tools available and lets it select which one to use.\n",
    "  * This is slightly better than the actual SQQE built-in to LlamaIndex, which cannot use multiple tools\n",
    "  * Each QueryEvent generates an `AnswerEvent`\n",
    "\n",
    "* AnswerEvents go to `combine_answers()`.\n",
    "  * This uses `self.collect_events()` to wait for every QueryEvent to return an answer.\n",
    "  * All the answers are then combined into a final prompt for the LLM to consolidate them into a single response\n",
    "  * A StopEvent is generated to return the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2db976a7-bc9d-44ea-97a1-785506aa116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryEvent(Event):\n",
    "    question : str\n",
    "\n",
    "class AnswerEvent(Event):\n",
    "    question : str\n",
    "    answer : str\n",
    "\n",
    "class SubQuestionQueryEngine(Workflow):\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def query(self, ctx:Context, ev:StartEvent) -> QueryEvent:\n",
    "        if(hasattr(ev, \"query\")):\n",
    "            ctx.data[\"original_query\"] = ev.query\n",
    "            print(f\"Query is {ctx.data['original_query']}\")\n",
    "\n",
    "        if (hasattr(ev,\"llm\")):\n",
    "            ctx.data[\"llm\"] = ev.llm\n",
    "\n",
    "        if (hasattr(ev,\"tools\")):\n",
    "            ctx.data[\"tools\"] = ev.tools\n",
    "\n",
    "        response = ctx.data[\"llm\"].complete(f\"\"\"\n",
    "            Given a user question, and a list of tools, output a list of\n",
    "            relevant subquestions, such that the answers to all the \n",
    "            sub-questions put together will answer the question.Respond in \n",
    "            pure JSON without any markdown, like this:\n",
    "            {{\n",
    "                \"sub_questions\": [\n",
    "                    \"What is the Net Profit of Infosys?\",\n",
    "                    \"What is the Net Loss of Infosys?\",\n",
    "                    \"What is percentage growth for Infosys?\"\n",
    "                ]\n",
    "            }})\n",
    "            Here is the User question: {ctx.data[\"original_query\"]}\n",
    "\n",
    "            And here is the list of tools: {ctx.data[\"tools\"]}\n",
    "            \"\"\")\n",
    "\n",
    "        response_obj = json.loads(str(response))\n",
    "        sub_questions = response_obj[\"sub_questions\"]\n",
    "\n",
    "        ctx.data[\"sub_question_count\"] = len(sub_questions)\n",
    "\n",
    "        for question in sub_questions:\n",
    "            self.send_event(QueryEvent(question=question))\n",
    "\n",
    "        return None\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def sub_question(self,ctx:Context, ev:QueryEvent) ->AnswerEvent:\n",
    "        print(f\"Sub-question is {ev.question}\")\n",
    "        agent = ReActAgent.from_tools(tools = ctx.data[\"tools\"],llm=ctx.data['llm'],verbose=True)\n",
    "        response = agent.chat(ev.question)\n",
    "        print(f\"-------------{response}----------\")\n",
    "\n",
    "        return AnswerEvent(question=ev.question,answer = str(response))\n",
    "\n",
    "    \n",
    "    @step(pass_context=True)\n",
    "    async def combine_answers(self,ctx:Context,ev:AnswerEvent) -> StopEvent | None:\n",
    "        ready  = ctx.collect_events(ev,[AnswerEvent]*ctx.data[\"sub_question_count\"])\n",
    "\n",
    "        if ready is None:\n",
    "            return None\n",
    "\n",
    "        answers = \"\\n\\n\".join([f\"Question : {event.question}: \\n Answer: {event.answer}\" for event in ready])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "            You are given an Overall question that has been split into sub-questions,\n",
    "            each of which has been answered. Combine the answers to all the sub-questions\n",
    "\n",
    "            Original question: {ctx.data['original_query']}\n",
    "\n",
    "            Sub-questions and answers:\n",
    "            {answers}\n",
    "            \"\"\"\n",
    "\n",
    "        print(f\"Final prompt is {prompt}\")\n",
    "        response = ctx.data[\"llm\"].complete(prompt)\n",
    "\n",
    "        print(\"Final response is\", response)\n",
    "\n",
    "        return StopEvent(result=str(response))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75b8a843-bb82-420b-9b16-dba4aa2a0c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub_Question_Query_Engine_workflow.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "draw_all_possible_flows(SubQuestionQueryEngine,filename=\"Sub_Question_Query_Engine_workflow.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cb2e80-8cc6-4d7b-bac2-e5b7028e6209",
   "metadata": {},
   "source": [
    "## Lets Display our Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61162d1c-4d3e-4f54-8ba1-2b3669eb5c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1100\"\n",
       "            height=\"400\"\n",
       "            src=\"Sub_Question_Query_Engine_workflow.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18e79b80850>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from IPython.display import HTML\n",
    "# work_flow_html = HTML(filename=\"Sub_Question_Query_Engine_workflow.html\")\n",
    "# display(work_flow_html)\n",
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame(src=\"Sub_Question_Query_Engine_workflow.html\", width=1100, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a8ac9-2d41-4336-bb6a-06fdf835208b",
   "metadata": {},
   "source": [
    "## Download data to a demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd5cae9-0f2f-467a-a24b-db23a6f2e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For Linux Users - \n",
    "# ! mkdir -p \"./data/infy_budgets\"\n",
    "# !wget \"https://www.infosys.com/investors/reports-filings/annual-report/form20f/documents/form20f-2022.pdf\"\n",
    "# !wget \"https://www.infosys.com/investors/reports-filings/annual-report/form20f/documents/form20f-2022.pdf\"\n",
    "# !wget \"https://www.infosys.com/investors/reports-filings/annual-report/form20f/documents/form20f-2022.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97e654e7-be67-4287-9ee4-a9cfefce4ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is DC49-8C99\n",
      "\n",
      " Directory of C:\\Users\\nilesh.chopda\\OneDrive - Calsoft Pvt Ltd\\Project\\Llamaindex-Workflow\\data\\infy_budgets\n",
      "\n",
      "08-08-2024  17:59    <DIR>          .\n",
      "08-08-2024  17:51    <DIR>          ..\n",
      "08-08-2024  17:46         1,509,673 2022-infybudget.pdf\n",
      "08-08-2024  17:46         2,543,407 2023-infybudget.pdf\n",
      "08-08-2024  17:45         5,359,420 2024-infybudget.pdf\n",
      "               3 File(s)      9,412,500 bytes\n",
      "               2 Dir(s)  76,496,584,704 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls \"data/infy_budgets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1817c6-ecd2-4ee1-88d7-aebec0111ada",
   "metadata": {},
   "source": [
    "## Lets Instantiate Our Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "145e0cf8-8685-457f-8bfe-5a3221195954",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48144689-ee1d-4ddb-8b26-a3690abe02c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Document Loaded for year 2022 ---------\n",
      "--------Indexing Document for year 2022 ---------\n",
      "--------Document Loaded for year 2023 ---------\n",
      "--------Indexing Document for year 2023 ---------\n",
      "--------Document Loaded for year 2024 ---------\n",
      "--------Indexing Document for year 2024 ---------\n",
      "--------Indexing Completed! ---------\n"
     ]
    }
   ],
   "source": [
    "# from llama_index.core.readers.file.base import SimpleDirectoryReader\n",
    "folder = \"data/infy_budgets/\"\n",
    "files = os.listdir(folder)\n",
    "\n",
    "query_engine_tools = []\n",
    "\n",
    "for file in files:\n",
    "    year = file.split(\"-\")[0]\n",
    "    index_persist_path = f\"storage/budget-{year}\"\n",
    "    print(f\"--------Document Loaded for year {year} ---------\")\n",
    "    if os.path.exists(index_persist_path):\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=index_persist_path)\n",
    "        index =load_index_from_storage(storage_context)\n",
    "\n",
    "    else:\n",
    "        documents = SimpleDirectoryReader(input_files=[folder + file]).load_data()\n",
    "        index = VectorStoreIndex.from_documents(documents)\n",
    "        index.storage_context.persist(index_persist_path)\n",
    "    print(f\"--------Indexing Document for year {year} ---------\")\n",
    "    engine = index.as_query_engine()\n",
    "    query_engine_tools.append(\n",
    "        QueryEngineTool(\n",
    "            query_engine=engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name = f\"budget_{year}\",\n",
    "                description = f\"Information about Infosys' profit loss statement in {year}\",\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "print(f\"--------Indexing Completed! ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a943c05-1e51-4c1c-b0d3-c57b1d44f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step query\n",
      "Query is How has the total amount of net profit for all 3 years?\n",
      "Step query produced no event\n",
      "Running step sub_question\n",
      "Sub-question is What is the net profit for the first year?\n",
      "> Running step 719f0305-6fb3-40eb-8526-f76e6cdfdddc. Step input: What is the net profit for the first year?\n",
      "\u001b[1;3;38;5;200mThought: The user is asking for the net profit for the first year. I need to use a tool to find this information.\n",
      "Action: budget_2022\n",
      "Action Input: {'input': 'net profit'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The decrease in net profit for fiscal 2022 compared to fiscal 2021 was primarily due to a decrease in operating profit by 1.5% and a decrease in other income by 0.3% as a percentage of revenue, partially offset by a decrease of 0.7% in tax expense as a percentage of revenue.\n",
      "\u001b[0m> Running step 8678a737-a8ba-46da-a9bd-fac7df141a02. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The provided information explains the reasons for the decrease in net profit for fiscal 2022 but does not provide the actual net profit value. I need to use the tool again to get the specific net profit amount for fiscal 2022.\n",
      "Action: budget_2022\n",
      "Action Input: {'input': 'net profit amount'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The net profit amount for the period is $2,637 million.\n",
      "\u001b[0m> Running step 6b159820-9f6e-41b2-b293-53669187ccba. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I now have the information needed to answer the user's question about the net profit for the first year.\n",
      "Answer: The net profit for the first year (fiscal 2022) is $2,637 million.\n",
      "\u001b[0m-------------The net profit for the first year (fiscal 2022) is $2,637 million.----------\n",
      "Step sub_question produced event AnswerEvent\n",
      "Running step sub_question\n",
      "Sub-question is What is the net profit for the second year?\n",
      "> Running step 11ae671d-7548-4f0f-963b-3e78f2463bcb. Step input: What is the net profit for the second year?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
      "Action: budget_2023\n",
      "Action Input: {'input': 'net profit'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 2983\n",
      "\u001b[0m> Running step 7b998ee7-1c0f-44bf-a24f-cedcc4da5244. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: The net profit for the second year (2023) is 2983.\n",
      "\u001b[0m-------------The net profit for the second year (2023) is 2983.----------\n",
      "Step sub_question produced event AnswerEvent\n",
      "Running step sub_question\n",
      "Sub-question is What is the net profit for the third year?\n",
      "> Running step 0ed64798-1fe4-435f-8d08-2459a0379650. Step input: What is the net profit for the third year?\n",
      "\u001b[1;3;38;5;200mThought: The user is asking for the net profit for the third year, which corresponds to the year 2024. I need to use a tool to find this information.\n",
      "Action: budget_2024\n",
      "Action Input: {'input': 'net profit'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 3,169\n",
      "\u001b[0m> Running step 5bcc1eff-8054-41a2-8270-f23e727f2673. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have obtained the net profit for the third year (2024), which is 3,169.\n",
      "Answer: The net profit for the third year (2024) is 3,169.\n",
      "\u001b[0m-------------The net profit for the third year (2024) is 3,169.----------\n",
      "Step sub_question produced event AnswerEvent\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Running step combine_answers\n",
      "Final prompt is \n",
      "            You are given an Overall question that has been split into sub-questions,\n",
      "            each of which has been answered. Combine the answers to all the sub-questions\n",
      "\n",
      "            Original question: How has the total amount of net profit for all 3 years?\n",
      "\n",
      "            Sub-questions and answers:\n",
      "            Question : What is the net profit for the first year?: \n",
      " Answer: The net profit for the first year (fiscal 2022) is $2,637 million.\n",
      "\n",
      "Question : What is the net profit for the second year?: \n",
      " Answer: The net profit for the second year (2023) is 2983.\n",
      "\n",
      "Question : What is the net profit for the third year?: \n",
      " Answer: The net profit for the third year (2024) is 3,169.\n",
      "            \n",
      "Final response is The total amount of net profit for all three years is the sum of the net profits for each individual year. \n",
      "\n",
      "For the first year (fiscal 2022), the net profit is $2,637 million. \n",
      "For the second year (2023), the net profit is $2,983 million. \n",
      "For the third year (2024), the net profit is $3,169 million.\n",
      "\n",
      "Adding these amounts together:\n",
      "\n",
      "$2,637 million + $2,983 million + $3,169 million = $8,789 million.\n",
      "\n",
      "Therefore, the total amount of net profit for all three years is $8,789 million.\n",
      "Step combine_answers produced event StopEvent\n"
     ]
    }
   ],
   "source": [
    "engine = SubQuestionQueryEngine(timeout=200,verbose=True)\n",
    "llm = OpenAI(model=\"gpt-4o\")\n",
    "result = await engine.run(\n",
    "    llm=llm,\n",
    "    tools = query_engine_tools,\n",
    "    query = \"How has the total amount of net profit for all 3 years?\"\n",
    ")\n",
    "\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21793d54-b3ce-41ad-b661-84e2e8ee2e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total amount of net profit for all three years is the sum of the net profits for each individual year. \n",
      "\n",
      "For the first year (fiscal 2022), the net profit is $2,637 million. \n",
      "For the second year (2023), the net profit is $2,983 million. \n",
      "For the third year (2024), the net profit is $3,169 million.\n",
      "\n",
      "Adding these amounts together:\n",
      "\n",
      "$2,637 million + $2,983 million + $3,169 million = $8,789 million.\n",
      "\n",
      "Therefore, the total amount of net profit for all three years is $8,789 million.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b088a-fca9-4952-b081-b11ec6ee4f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74258de-6820-4e18-8429-f971adeac627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645e606-86ab-4c1f-925d-2c3c082605df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
